{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name: str):\n",
    "    path = f\"../datasets/{dataset_name}\"\n",
    "    return pd.read_csv(path, sep=';', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = get_dataset(\"1_social_media_account.csv\")\n",
    "news = get_dataset(\"2_news.csv\")\n",
    "news_users = get_dataset(\"3_post.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing=0.01\n",
    "omega=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = news[\"ground_truth_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.3\n",
    "X_train_news, X_test_news, _, _ = train_test_split(news, labels, test_size=test_size, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armazena as notícias compartilhadas por cada usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_users = pd.merge(X_train_news, news_users, left_on=\"id_news\", right_on=\"id_news\")\n",
    "test_news_users  = pd.merge(X_test_news, news_users, left_on=\"id_news\", right_on=\"id_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conta a qtde de noticias fake e ~fake presentes no conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_V = news[\"ground_truth_label\"].value_counts()[0]\n",
    "qtd_F = news[\"ground_truth_label\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtra apenas os usuários que não estão em ambos os conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_users = train_news_users[train_news_users[\"id_social_media_account\"].isin(test_news_users[\"id_social_media_account\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializa os parâmetros dos usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "totR            = 0\n",
    "totF            = 0\n",
    "alphaN          = totR + smoothing\n",
    "umAlphaN        = ((totF + smoothing) / (qtd_F + smoothing)) * (qtd_V + smoothing)\n",
    "betaN           = (umAlphaN * (totR + smoothing)) / (totF + smoothing)\n",
    "umBetaN         = totF + smoothing\n",
    "probAlphaN      = alphaN / (alphaN + umAlphaN)\n",
    "probUmAlphaN    = 1 - probAlphaN\n",
    "probBetaN       = betaN / (betaN + umBetaN)\n",
    "probUmBetaN     = 1 - probBetaN\n",
    "users[\"probAlphaN\"]    = probAlphaN\n",
    "users[\"probUmAlphaN\"]  = probUmAlphaN\n",
    "users[\"probBetaN\"]     = probBetaN\n",
    "users[\"probUmBetaN\"]   = probUmBetaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICS:\n",
    "\n",
    "    def __init__(self, laplace_smoothing=0.01, omega=0.5):\n",
    "\n",
    "        self.__users = get_dataset(\"1_social_media_account.csv\")\n",
    "        self.__news  = get_dataset(\"2_news.csv\")\n",
    "        self.__news_users = get_dataset(\"3_post.csv\")\n",
    "\n",
    "        self.__smoothing  = laplace_smoothing\n",
    "        self.__omega      = omega\n",
    "\n",
    "    def __init_params(self, test_size = 0.3):\n",
    "\n",
    "        news = self.__news[self.__news['ground_truth_label'].notnull()]\n",
    "        if not len(news.index):\n",
    "            return 0\n",
    "\n",
    "        # divide 'self.__news_users' em treino e teste.\n",
    "        labels = news[\"ground_truth_label\"]\n",
    "        self.__X_train_news, self.__X_test_news, _, _ = train_test_split(news, labels, test_size=test_size, stratify=labels)\n",
    "\n",
    "        # # armazena em 'self.__train_news_users' as notícias compartilhadas por cada usuário.\n",
    "        self.__train_news_users = pd.merge(self.__X_train_news, self.__news_users, left_on=\"id_news\", right_on=\"id_news\")\n",
    "        self.__test_news_users  = pd.merge(self.__X_test_news, self.__news_users, left_on=\"id_news\", right_on=\"id_news\")\n",
    "\n",
    "        # conta a qtde de noticias verdadeiras e falsas presentes no conjunto de treino.\n",
    "        self.__qtd_V = self.__news[\"ground_truth_label\"].value_counts()[0]\n",
    "        self.__qtd_F = self.__news[\"ground_truth_label\"].value_counts()[1]\n",
    "\n",
    "        # filtra apenas os usuários que não estão em ambos os conjuntos de treino e teste.\n",
    "        self.__train_news_users = self.__train_news_users[self.__train_news_users[\"id_social_media_account\"].isin(self.__test_news_users[\"id_social_media_account\"])]\n",
    "\n",
    "        # inicializa os parâmetros dos usuários.\n",
    "        totR            = 0\n",
    "        totF            = 0\n",
    "        alphaN          = totR + self.__smoothing\n",
    "        umAlphaN        = ((totF + self.__smoothing) / (self.__qtd_F + self.__smoothing)) * (self.__qtd_V + self.__smoothing)\n",
    "        betaN           = (umAlphaN * (totR + self.__smoothing)) / (totF + self.__smoothing)\n",
    "        umBetaN         = totF + self.__smoothing\n",
    "        probAlphaN      = alphaN / (alphaN + umAlphaN)\n",
    "        probUmAlphaN    = 1 - probAlphaN\n",
    "        probBetaN       = betaN / (betaN + umBetaN)\n",
    "        probUmBetaN     = 1 - probBetaN\n",
    "        self.__users[\"probAlphaN\"]    = probAlphaN\n",
    "        self.__users[\"probUmAlphaN\"]  = probUmAlphaN\n",
    "        self.__users[\"probBetaN\"]     = probBetaN\n",
    "        self.__users[\"probUmBetaN\"]   = probUmBetaN\n",
    "\n",
    "        return 1\n",
    "\n",
    "\n",
    "    def __assess(self):\n",
    "        \"\"\"\n",
    "        etapa de avaliação: avalia a notícia com base nos parâmetros de cada usuário obtidos na etapa de treinamento.\n",
    "        \"\"\"\n",
    "        predicted_labels = []\n",
    "        unique_id_news   = self.__test_news_users[\"id_news\"].unique()\n",
    "\n",
    "        for newsId in unique_id_news:\n",
    "            # recupera os ids de usuário que compartilharam a notícia representada por 'newsId'.\n",
    "            usersWhichSharedTheNews = list(self.__news_users[\"id_social_media_account\"].loc[self.__news_users[\"id_news\"] == newsId])\n",
    "\n",
    "            productAlphaN    = 1.0\n",
    "            productUmAlphaN  = 1.0\n",
    "            productBetaN     = 1.0\n",
    "            productUmBetaN   = 1.0\n",
    "\n",
    "            for userId in usersWhichSharedTheNews:\n",
    "                i = self.__users.loc[self.__users[\"id_social_media_account\"] == userId].index[0]\n",
    "\n",
    "                productAlphaN   = productAlphaN  * self.__users.at[i, \"probAlphaN\"]\n",
    "                productUmBetaN  = productUmBetaN * self.__users.at[i, \"probUmBetaN\"]\n",
    "\n",
    "            # inferência bayesiana\n",
    "            reputation_news_tn = (self.__omega * productAlphaN * productUmAlphaN) * 100\n",
    "            reputation_news_fn = ((1 - self.__omega) * productBetaN * productUmBetaN) * 100\n",
    "\n",
    "            if reputation_news_tn >= reputation_news_fn:\n",
    "                predicted_labels.append(0)\n",
    "            else:\n",
    "                predicted_labels.append(1)\n",
    "\n",
    "        # mostra os resultados da matriz de confusão e acurácia.\n",
    "        gt = self.__X_test_news[\"ground_truth_label\"].tolist()\n",
    "        print(confusion_matrix(gt, predicted_labels))\n",
    "        print(accuracy_score(gt, predicted_labels))\n",
    "\n",
    "    def fit(self, test_size = 0.3):\n",
    "        \"\"\"\n",
    "        Etapa de treinamento: calcula os parâmetros de cada usuário a partir do Implict Crowd Signals.\n",
    "        \"\"\"\n",
    "        status_code = self.__init_params(test_size)\n",
    "        if not status_code:\n",
    "            return 0\n",
    "\n",
    "        i = 0\n",
    "        users_unique = self.__train_news_users[\"id_social_media_account\"].unique()\n",
    "        total = len(users_unique)\n",
    "\n",
    "        for userId in users_unique:\n",
    "            i = i + 1\n",
    "            print(\"\", end=\"Progresso do treinamento: {0:.2f}%\\r\".format(float((i / total) * 100)), flush=True)\n",
    "\n",
    "            # obtém os labels das notícias compartilhadas por cada usuário.\n",
    "            newsSharedByUser = list(self.__train_news_users[\"ground_truth_label\"].loc[self.__train_news_users[\"id_social_media_account\"] == userId])\n",
    "\n",
    "            # calcula a matriz de opinião para cada usuário.\n",
    "            totR        = newsSharedByUser.count(0)\n",
    "            totF        = newsSharedByUser.count(1)\n",
    "            alphaN      = totR + self.__smoothing\n",
    "            umAlphaN    = ((totF + self.__smoothing) / (self.__qtd_F + self.__smoothing)) * (self.__qtd_V + self.__smoothing)\n",
    "            betaN       = (umAlphaN * (totR + self.__smoothing)) / (totF + self.__smoothing)\n",
    "            umBetaN     = totF + self.__smoothing\n",
    "\n",
    "            # calcula as probabilidades para cada usuário.\n",
    "            probAlphaN      = alphaN / (alphaN + umAlphaN)\n",
    "            probUmAlphaN    = 1 - probAlphaN\n",
    "            probBetaN       = betaN / (betaN + umBetaN)\n",
    "            probUmBetaN     = 1 - probBetaN\n",
    "            self.__users.loc[self.__users[\"id_social_media_account\"] == userId, \"probAlphaN\"]   = probAlphaN\n",
    "            self.__users.loc[self.__users[\"id_social_media_account\"] == userId, \"probBetaN\"]    = probBetaN\n",
    "            self.__users.loc[self.__users[\"id_social_media_account\"] == userId, \"probUmAlphaN\"] = probUmAlphaN\n",
    "            self.__users.loc[self.__users[\"id_social_media_account\"] == userId, \"probUmBetaN\"]  = probUmBetaN\n",
    "\n",
    "        self.__assess()\n",
    "        return self.__users\n",
    "\n",
    "    def predict(self, id_news):\n",
    "        \"\"\"\n",
    "        Classifica uma notícia usando o ICS.\n",
    "        \"\"\"\n",
    "\n",
    "        # 17/06/2021\n",
    "        # usersWhichSharedTheNews = self.__dao.get_users_which_shared_the_news(id_news)\n",
    "        usersWhichSharedTheNews = list(self.__news_users[\"id_social_media_account\"].loc[self.__news_users[\"id_news\"] == id_news])\n",
    "\n",
    "        productAlphaN    = 1.0\n",
    "        productUmAlphaN  = 1.0\n",
    "        productBetaN     = 1.0\n",
    "        productUmBetaN   = 1.0\n",
    "\n",
    "        # 17/06/2021\n",
    "        for userId in usersWhichSharedTheNews:\n",
    "            i = self.__users.loc[self.__users[\"id_social_media_account\"] == userId].index[0]\n",
    "            productAlphaN   = productAlphaN  * self.__users.at[i, \"probAlphaN\"]\n",
    "            productUmBetaN  = productUmBetaN * self.__users.at[i, \"probUmBetaN\"]\n",
    "\n",
    "\n",
    "#        for _, row in usersWhichSharedTheNews.iterrows():\n",
    "#            productAlphaN   = productAlphaN  * row[\"probalphan\"]\n",
    "#            productUmBetaN  = productUmBetaN * row[\"probumbetan\"]\n",
    "\n",
    "        # inferência bayesiana\n",
    "        reputation_news_tn = (self.__omega * productAlphaN * productUmAlphaN) * 100\n",
    "        reputation_news_fn = ((1 - self.__omega) * productBetaN * productUmBetaN) * 100\n",
    "\n",
    "        # calculando o grau de probabilidade da predição.\n",
    "        total = reputation_news_tn + reputation_news_fn\n",
    "        prob = 0\n",
    "\n",
    "        if reputation_news_tn >= reputation_news_fn:\n",
    "            prob = reputation_news_tn / total\n",
    "            return 0, prob # notícia classificada como legítima.\n",
    "        else:\n",
    "            prob = reputation_news_fn / total\n",
    "            return 1, prob # notícia classificada como fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ics = ICS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  3]o do treinamento: 100.00%\n",
      " [10 80]]\n",
      "0.9277777777777778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_social_media_account</th>\n",
       "      <th>probAlphaN</th>\n",
       "      <th>probUmAlphaN</th>\n",
       "      <th>probBetaN</th>\n",
       "      <th>probUmBetaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999093</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.999093</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.990196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16019</th>\n",
       "      <td>16020</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16020</th>\n",
       "      <td>16021</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16021</th>\n",
       "      <td>16022</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>16023</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>16024</td>\n",
       "      <td>0.996689</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.996689</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16024 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_social_media_account  probAlphaN  probUmAlphaN  probBetaN  \\\n",
       "0                            1    0.999093      0.000907   0.999093   \n",
       "1                            2    0.009804      0.990196   0.009804   \n",
       "2                            3    0.500000      0.500000   0.500000   \n",
       "3                            4    0.500000      0.500000   0.500000   \n",
       "4                            5    0.500000      0.500000   0.500000   \n",
       "...                        ...         ...           ...        ...   \n",
       "16019                    16020    0.500000      0.500000   0.500000   \n",
       "16020                    16021    0.500000      0.500000   0.500000   \n",
       "16021                    16022    0.500000      0.500000   0.500000   \n",
       "16022                    16023    0.500000      0.500000   0.500000   \n",
       "16023                    16024    0.996689      0.003311   0.996689   \n",
       "\n",
       "       probUmBetaN  \n",
       "0         0.000907  \n",
       "1         0.990196  \n",
       "2         0.500000  \n",
       "3         0.500000  \n",
       "4         0.500000  \n",
       "...            ...  \n",
       "16019     0.500000  \n",
       "16020     0.500000  \n",
       "16021     0.500000  \n",
       "16022     0.500000  \n",
       "16023     0.003311  \n",
       "\n",
       "[16024 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ics.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9991639211271337\n"
     ]
    }
   ],
   "source": [
    "previsao, prob = ics.predict(333)\n",
    "print(previsao, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
